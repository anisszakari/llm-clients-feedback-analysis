# ğŸ“¢ Feedback Analysis Project

Ce projet analyse les **feedbacks clients** en utilisant un **LLM** (Large Language Model) pour dÃ©tecter le **sentiment**. 
Si un feedback est nÃ©gatif, un **email** est envoyÃ© automatiquement Ã  l'Ã©quipe support et au client.  
Le tout est dÃ©ployÃ© sur **Google Cloud Run** avec **Terraform** et une pipeline **CI/CD via GitHub Actions**.

---

## ğŸ“Œ **Architecture du projet**
### ğŸ—ï¸ **Les services :**
1. **`llm_analysis_service`** ğŸ§   
   - Analyse le feedback avec un **LLM** (ex: OpenAI GPT-4).
   - Stocke les rÃ©sultats dans **BigQuery**.
   - Publie lâ€™analyse sur **Pub/Sub**.

2. **`negative_feedback_handler`** ğŸš¨  
   - RÃ©cupÃ¨re les feedbacks nÃ©gatifs via **Pub/Sub**.
   - Envoie un **email** au support + au client concernÃ©.

---

## ğŸ› ï¸ **Installation & DÃ©ploiement**

### **1ï¸âƒ£ PrÃ©requis**  
- **Google Cloud SDK** installÃ© ([lien](https://cloud.google.com/sdk/docs/install))
- Un projet **GCP** avec :
  - **Cloud Run** activÃ©
  - **BigQuery** et **Pub/Sub** configurÃ©s
  - **IAM Service Account** avec les permissions nÃ©cessaires  
- **Docker** installÃ©  
- **Terraform** installÃ©  

### **2ï¸âƒ£ Cloner le repo**  
```sh
git clone https://github.com/anisszakari/llm-clients-feedback-analysis.git
cd llm-clients-feedback-analysis
```

### **3ï¸âƒ£ Configurer les variables GCP**  
Dans **GitHub Secrets** (si CI/CD) ou en local dans `.env` :  

| Variable | Description |
|----------|-------------|
| `GCP_PROJECT_ID` | ID du projet GCP |
| `OPENAI_API_KEY` | ClÃ© API OpenAI |
| `SENDGRID_API_KEY` | ClÃ© API SendGrid |

---

## ğŸš€ **DÃ©ploiement Automatique (CI/CD)**  

### **1ï¸âƒ£ Configuration GitHub Actions**  
Dans **GitHub > Repo > Settings > Secrets** â Ajouter :  
- `GCP_PROJECT_ID`  
- `GCP_SA_KEY` (clÃ© JSON du Service Account)  
- `OPENAI_API_KEY`  
- `SENDGRID_API_KEY`  

### **2ï¸âƒ£ Push sur `main`**  
Ã€ chaque push sur `main`, GitHub Actions :  
âœ… **Construit et push lâ€™image Docker sur GCR**  
âœ… **DÃ©ploie sur Cloud Run**  

---

## ğŸš€ **DÃ©ploiement Manuel** (Sans CI/CD)  

### **1ï¸âƒ£ DÃ©ploiement avec Terraform**  
```sh
terraform init
terraform apply
```

### **2ï¸âƒ£ DÃ©ploiement avec un script**  
```sh
chmod +x deploy.sh
./deploy.sh
```

---

## ğŸ“¡ **Exemple d'utilisation API**

### **Analyser un feedback**  
```sh
curl -X POST "https://llm-analysis-service-url/analyze_feedback/"      -H "Content-Type: application/json"      -d '{"feedback_id": "123", "feedback_text": "Votre service est horrible !"}'
```
ğŸ“Œ **RÃ©ponse attendue :**  
```json
{
  "feedback_id": "123",
  "sentiment": "NÃ©gatif"
}
```

---

